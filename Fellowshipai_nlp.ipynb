{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd2a3fa",
   "metadata": {},
   "source": [
    "# Fellowship.ai Internship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b193d",
   "metadata": {},
   "source": [
    "\n",
    "**Candidate Name : MASNA**\n",
    "\n",
    "**NLP Challenge:**\n",
    "\n",
    "IMDB Dataset of 50K Movie Reviews to perform Sentiment analysis\n",
    "About Dataset\n",
    "IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "afa66ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "798d009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d835bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Top 5 Rows\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cc59e12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41617</th>\n",
       "      <td>When taken as a whole for its ideas and dissec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14531</th>\n",
       "      <td>Alicianne (Laurel Barnett) becomes a live in b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18910</th>\n",
       "      <td>with very little screen time and money, Dan Ka...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27745</th>\n",
       "      <td>I gave this movie a 10 because it needed to be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25203</th>\n",
       "      <td>A truly excellent look at the world and the re...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23700</th>\n",
       "      <td>Semper Fi! I saw \"The D.I.\" in 1957. Two-and-a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12863</th>\n",
       "      <td>Army private Gene Kelly, who's also a talented...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19350</th>\n",
       "      <td>This film is about the encounters of 7 couples...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13648</th>\n",
       "      <td>first, someone mentioned here that because thi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18727</th>\n",
       "      <td>It's easy to forget, once later series had dev...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "41617  When taken as a whole for its ideas and dissec...  positive\n",
       "14531  Alicianne (Laurel Barnett) becomes a live in b...  negative\n",
       "18910  with very little screen time and money, Dan Ka...  positive\n",
       "27745  I gave this movie a 10 because it needed to be...  positive\n",
       "25203  A truly excellent look at the world and the re...  positive\n",
       "23700  Semper Fi! I saw \"The D.I.\" in 1957. Two-and-a...  positive\n",
       "12863  Army private Gene Kelly, who's also a talented...  negative\n",
       "19350  This film is about the encounters of 7 couples...  negative\n",
       "13648  first, someone mentioned here that because thi...  positive\n",
       "18727  It's easy to forget, once later series had dev...  positive"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Random 10 Rows\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2223346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "903237c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Printing Dataset Information\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22fe98e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Null Values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ea25482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Duplicated Values\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99022733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicated Values\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f69a3eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Duplicated Values After Removing Duplicated\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d42e0fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing First review column\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e55989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    24884\n",
       "negative    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "46d1f618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Pie Chart of Sentiment Column\n",
    "\n",
    "df.sentiment.value_counts().plot(kind='pie', autopct='%1.1f%%', title='Pie Chart of Sentiment Column', legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3e1d2",
   "metadata": {},
   "source": [
    "**Text Cleaning**\n",
    "\n",
    "Removing Html tags\n",
    "\n",
    "Converting every thing to lowercase\n",
    "\n",
    "Removing special characters\n",
    "\n",
    "Removing Stop words\n",
    "\n",
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "246c7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In sentiment column converting positive to 1 and negative to 0\n",
    "\n",
    "df.sentiment = df.sentiment.replace({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87377fda",
   "metadata": {},
   "source": [
    "**Removing Html tag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d76a1326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row before removing html tag\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2a15d1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing html tag in First ROW \n",
    "\n",
    "import re\n",
    "clean = re.compile('<.*?>')\n",
    "\n",
    "# In Review column first row after removing html tag\n",
    "\n",
    "re.sub(clean, '',  df.iloc[0].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ccba09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to clean html tags\n",
    "\n",
    "def clean_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f7cbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling Removing html tags function\n",
    "\n",
    "df.review = df.review.apply(clean_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d14ad",
   "metadata": {},
   "source": [
    "**Converting every thing to lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "47f19a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting everything to lower\n",
    "\n",
    "def convert_lower(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "194f6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling convert_lower function\n",
    "\n",
    "df.review = df.review.apply(convert_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4a64065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f337498",
   "metadata": {},
   "source": [
    "**Removing special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "af166269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove special characters\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    clean = re.compile('[^a-zA-Z ]')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8f9a6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling remove_special_chars function\n",
    "\n",
    "df.review = df.review.apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "89f6eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the other reviewers has mentioned that after watching just  oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ec648cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ideapad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17e792",
   "metadata": {},
   "source": [
    "**Removing Stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "71fd5abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5ec34f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords from Review Column\n",
    "\n",
    "sw_list = stopwords.words('english')\n",
    "\n",
    "df.review = df.review.apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e9849ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home manyaryans muslims gangstas latinos christians italians irish moreso scuffles death stares dodgy dealings shady agreements never far awayi would say main appeal show due fact goes shows wouldnt dare forget pretty pictures painted mainstream audiences forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards wholl sold nickel inmates wholl kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row after removing Stopwords\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f87d40",
   "metadata": {},
   "source": [
    "**Applying Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c0bfaa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ideapad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ideapad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ideapad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9bff8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e3856fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Lemmatization\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_text = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7516128c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home manyaryans muslim gangsta latino christian italian irish moreso scuffle death stare dodgy dealing shady agreement never far awayi would say main appeal show due fact go show wouldnt dare forget pretty picture painted mainstream audience forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard wholl sold nickel inmate wholl kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row before applying Lemmatization Function\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c150cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Lemmatization Function\n",
    "\n",
    "df.review = df.review.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7a60ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home manyaryans muslim gangsta latino christian italian irish moreso scuffle death stare dodgy dealing shady agreement never far awayi would say main appeal show due fact go show wouldnt dare forget pretty picture painted mainstream audience forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard wholl sold nickel inmate wholl kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row after applying Lemmatization Function\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1a988585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df.review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fa87a7",
   "metadata": {},
   "source": [
    "**Model Building**\n",
    "\n",
    "In summary, the steps involved in building a machine learning model include data preparation, splitting the data into training, validation, and test sets, choosing an appropriate model, training the model on the training data, evaluating the model on the validation and test sets, fine-tuning the model based on the evaluation results, and finally deploying the model for making predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eb0ddecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e9353e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mentioned watching oz episode you...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there family little boy jake think t...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job wasnt creative or...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary school nu...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movie high art fan expec...\n",
       "Name: clean_text, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6876584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8893d6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 49582, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e741e4",
   "metadata": {},
   "source": [
    "**Train Test Split**\n",
    "\n",
    "Train-test split is a technique used in machine learning to evaluate the performance of a model on new, unseen data. It involves splitting the available data into two subsets - a training set and a test set. The model is trained on the training set and its performance is evaluated on the test set. This allows the model to learn patterns from the training data and be evaluated on how well it can generalize to new data. The goal of train-test split is to ensure that the model is not overfitting the training data and can perform well on new data. Typically, around 70-80% of the data is used for training, and the remaining 20-30% is used for testing. Cross-validation is another technique that can be used in combination with train-test split to further evaluate the model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "afa2e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36142eea",
   "metadata": {},
   "source": [
    "**Bag of Word Representation**\n",
    "\n",
    "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "\n",
    "We will use CountVectorizer **to convert text into a matrix of token count.**\n",
    "\n",
    "Bag of Words: https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
    "\n",
    "Code Example: https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
    "\n",
    "**We are going to perform below mentioned steps to understand the entire process:**\n",
    "a. Converting text to numerical vectors with the help of CountVectorizer\n",
    "b. Understand fit and transform\n",
    "c. Looking at vocabulary_\n",
    "d. Converting sparse matrix to dense matrix using toarray()\n",
    "e. Understanding n_gram\n",
    "\n",
    "**Advantages**\n",
    "It is simple to understand and implement like OneHotEncoding.\n",
    "We have a fixed length encoding for any sequence of arbitrary length.\n",
    "Documents with same words/vocabulary will have similar representation. So if two documents have a similar vocabulary, theyll be closer to each other in the vector space and vice versa.\n",
    "**Disadvantages**\n",
    "The size of vector increases with the size of the vocabulary. Thus, sparsity continues to be a problem. One way to control it is by limiting the vocabulary to n number of the most frequent words.\n",
    "It does not capture the similarity between different words that mean the same thing. i.e. Semantic Meaning is not captured.\n",
    "a. \"walk\", \"walked\", and \"walking\". BoW vectors of all three tokens will be equally apart.\n",
    "b. \"search\" and \"explore\" are synonyms. BoW won't capture the semantic similarity of these words.\n",
    "\n",
    "This representation does not have any way to handle out of vocabulary (OOV) words (i.e., new words that were not seen in the corpus that was used to build the vectorizer).\n",
    "As the name indicates, it is a bag of words. Word order information is lost in this representation. One way to control it is by using n-grams.\n",
    "It suffers from **curse of high dimensionality.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "46692706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "91d9db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "59216ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = vocab.fit_transform(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e7cda844",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = vocab.transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc4c4432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39665x175730 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3834096 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "59c30177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9917x175730 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 928119 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d540b9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'really': 125331,\n",
       " 'liked': 88528,\n",
       " 'movie': 100985,\n",
       " 'emporers': 47127,\n",
       " 'new': 104767,\n",
       " 'groove': 65264,\n",
       " 'watching': 168207,\n",
       " 'like': 88505,\n",
       " 'coming': 29527,\n",
       " 'home': 71897,\n",
       " 'seeing': 135463,\n",
       " 'wife': 170819,\n",
       " 'relation': 126792,\n",
       " 'llama': 89485,\n",
       " 'seriously': 136995,\n",
       " 'bad': 11206,\n",
       " 'club': 28253,\n",
       " 'dread': 43477,\n",
       " 'super': 149487,\n",
       " 'trooper': 159873,\n",
       " 'supposed': 149909,\n",
       " 'write': 173180,\n",
       " 'line': 88790,\n",
       " 'dont': 42488,\n",
       " 'even': 49692,\n",
       " 'know': 84300,\n",
       " 'else': 46623,\n",
       " 'say': 133042,\n",
       " 'laughed': 86406,\n",
       " 'couple': 32713,\n",
       " 'time': 156315,\n",
       " 'drinking': 43742,\n",
       " 'least': 86941,\n",
       " 'funny': 59763,\n",
       " 'drunk': 44007,\n",
       " 'maybe': 94844,\n",
       " 'regular': 126554,\n",
       " 'cartoon': 23174,\n",
       " 'people': 114859,\n",
       " 'arent': 8046,\n",
       " 'either': 46136,\n",
       " 'way': 168496,\n",
       " 'stick': 146532,\n",
       " 'want': 167554,\n",
       " 'llamathemed': 89486,\n",
       " 'right': 129209,\n",
       " 'decided': 36928,\n",
       " 'watch': 168113,\n",
       " 'noted': 106764,\n",
       " 'scariest': 133336,\n",
       " 'ever': 49788,\n",
       " 'thats': 153732,\n",
       " 'expected': 51002,\n",
       " 'unfortunately': 162710,\n",
       " 'found': 58178,\n",
       " 'didnt': 39489,\n",
       " 'single': 140304,\n",
       " 'scary': 133368,\n",
       " 'moment': 99359,\n",
       " 'im': 75029,\n",
       " 'kind': 83732,\n",
       " 'person': 115565,\n",
       " 'jump': 81872,\n",
       " 'easily': 45191,\n",
       " 'nothing': 106809,\n",
       " 'terrible': 153192,\n",
       " 'clichs': 27853,\n",
       " 'every': 49963,\n",
       " 'jumpmoment': 81886,\n",
       " 'incredibly': 76103,\n",
       " 'obvious': 108021,\n",
       " 'pro': 121075,\n",
       " 'would': 172960,\n",
       " 'music': 102682,\n",
       " 'odd': 108240,\n",
       " 'scene': 133475,\n",
       " 'actually': 1708,\n",
       " 'shot': 138910,\n",
       " 'well': 169177,\n",
       " 'last': 86088,\n",
       " 'open': 110149,\n",
       " 'door': 42580,\n",
       " 'see': 135423,\n",
       " 'tun': 160362,\n",
       " 'reflection': 126339,\n",
       " 'swing': 150754,\n",
       " 'back': 10964,\n",
       " 'ghost': 61989,\n",
       " 'shoulder': 139003,\n",
       " 'overall': 111758,\n",
       " 'added': 1814,\n",
       " 'jhorror': 80912,\n",
       " 'genre': 61502,\n",
       " 'allaround': 4053,\n",
       " 'lacked': 85293,\n",
       " 'creativity': 33515,\n",
       " 'scare': 133281,\n",
       " 'hard': 67686,\n",
       " 'going': 63242,\n",
       " 'lady': 85388,\n",
       " 'shanghai': 137835,\n",
       " 'film': 54725,\n",
       " 'could': 32481,\n",
       " 'without': 171657,\n",
       " 'studio': 148064,\n",
       " 'interference': 77861,\n",
       " 'orson': 110828,\n",
       " 'welles': 169306,\n",
       " 'prime': 120887,\n",
       " 'interest': 77748,\n",
       " 'point': 118192,\n",
       " 'raise': 124236,\n",
       " 'money': 99512,\n",
       " 'theater': 153808,\n",
       " 'indeed': 76152,\n",
       " 'funding': 59655,\n",
       " 'project': 121595,\n",
       " 'drove': 43883,\n",
       " 'seek': 135495,\n",
       " 'acting': 1124,\n",
       " 'job': 81074,\n",
       " 'made': 91870,\n",
       " 'soon': 143248,\n",
       " 'exwife': 51694,\n",
       " 'rita': 129535,\n",
       " 'hayworth': 68477,\n",
       " 'harry': 67991,\n",
       " 'cohn': 28733,\n",
       " 'fearful': 53670,\n",
       " 'ritas': 129541,\n",
       " 'image': 75033,\n",
       " 'held': 69205,\n",
       " 'release': 126863,\n",
       " 'one': 109454,\n",
       " 'yearthe': 174233,\n",
       " 'plot': 117790,\n",
       " 'concern': 30371,\n",
       " 'irish': 78551,\n",
       " 'sailor': 131998,\n",
       " 'michael': 97141,\n",
       " 'ohara': 108852,\n",
       " 'fall': 52400,\n",
       " 'love': 90595,\n",
       " 'stunning': 148204,\n",
       " 'short': 138806,\n",
       " 'blond': 16617,\n",
       " 'hair': 66562,\n",
       " 'husband': 73978,\n",
       " 'known': 84369,\n",
       " 'criminal': 33877,\n",
       " 'attorney': 9739,\n",
       " 'arthur': 8604,\n",
       " 'bannister': 12055,\n",
       " 'everett': 49836,\n",
       " 'sloane': 141460,\n",
       " 'crippled': 33940,\n",
       " 'inside': 77184,\n",
       " 'hire': 71110,\n",
       " 'work': 172375,\n",
       " 'yacht': 173792,\n",
       " 'drawn': 43454,\n",
       " 'deeper': 37139,\n",
       " 'web': 168866,\n",
       " 'murder': 102478,\n",
       " 'deceitthe': 36866,\n",
       " 'move': 100931,\n",
       " 'snail': 142005,\n",
       " 'pace': 112565,\n",
       " 'though': 155438,\n",
       " 'agree': 3128,\n",
       " 'poster': 119379,\n",
       " 'today': 157163,\n",
       " 'criticized': 34029,\n",
       " 'taking': 151467,\n",
       " 'build': 20406,\n",
       " 'still': 146599,\n",
       " 'drag': 43222,\n",
       " 'fun': 59603,\n",
       " 'house': 73042,\n",
       " 'fantastic': 52813,\n",
       " 'wanted': 167560,\n",
       " 'believe': 14111,\n",
       " 'cut': 34956,\n",
       " 'shame': 137775,\n",
       " 'photography': 116265,\n",
       " 'throughout': 155900,\n",
       " 'atmospheric': 9495,\n",
       " 'bold': 17324,\n",
       " 'stylishwelles': 148421,\n",
       " 'excellent': 50397,\n",
       " 'actor': 1452,\n",
       " 'handsome': 67266,\n",
       " 'youth': 174830,\n",
       " 'charismatic': 25208,\n",
       " 'possessing': 119256,\n",
       " 'magnificent': 92204,\n",
       " 'voice': 166758,\n",
       " 'technique': 152439,\n",
       " 'many': 93399,\n",
       " 'almost': 4520,\n",
       " 'doesnt': 41961,\n",
       " 'trust': 160104,\n",
       " 'take': 151410,\n",
       " 'develop': 38889,\n",
       " 'character': 24869,\n",
       " 'instead': 77368,\n",
       " 'relies': 126977,\n",
       " 'external': 51523,\n",
       " 'accent': 647,\n",
       " 'fake': 52338,\n",
       " 'nose': 106644,\n",
       " 'tomorrow': 157575,\n",
       " 'forever': 57671,\n",
       " 'director': 40260,\n",
       " 'get': 61843,\n",
       " 'deeply': 37149,\n",
       " 'felt': 54014,\n",
       " 'performance': 115188,\n",
       " 'contrast': 31431,\n",
       " 'compulsion': 30230,\n",
       " 'show': 139051,\n",
       " 'master': 94286,\n",
       " 'pure': 122903,\n",
       " 'technical': 152416,\n",
       " 'phone': 116180,\n",
       " 'quadruple': 123224,\n",
       " 'duty': 44713,\n",
       " 'star': 145678,\n",
       " 'cowriter': 33005,\n",
       " 'narrator': 103599,\n",
       " 'sporting': 144932,\n",
       " 'completely': 30058,\n",
       " 'unnecessary': 163230,\n",
       " 'looking': 90107,\n",
       " 'intense': 77630,\n",
       " 'fast': 53232,\n",
       " 'characterization': 24955,\n",
       " 'nevertheless': 104747,\n",
       " 'always': 4909,\n",
       " 'compellingthe': 29953,\n",
       " 'supporting': 149892,\n",
       " 'player': 117518,\n",
       " 'including': 75950,\n",
       " 'sloan': 141459,\n",
       " 'glenn': 62759,\n",
       " 'anders': 5728,\n",
       " 'gorgeous': 63965,\n",
       " 'softvoiced': 142620,\n",
       " 'singing': 140291,\n",
       " 'dubbed': 44101,\n",
       " 'anita': 6175,\n",
       " 'elli': 46551,\n",
       " 'usual': 164460,\n",
       " 'complete': 30044,\n",
       " 'goddess': 63061,\n",
       " 'great': 64720,\n",
       " 'screen': 134518,\n",
       " 'presence': 120475,\n",
       " 'sad': 131760,\n",
       " 'life': 88126,\n",
       " 'vibrant': 165692,\n",
       " 'beautyany': 13272,\n",
       " 'directed': 40158,\n",
       " 'worth': 172902,\n",
       " 'exception': 50449,\n",
       " 'leaf': 86866,\n",
       " 'viewer': 166003,\n",
       " 'frustrated': 59347,\n",
       " 'ambersons': 5108,\n",
       " 'within': 171635,\n",
       " 'system': 151136,\n",
       " 'artist': 8653,\n",
       " 'given': 62586,\n",
       " 'freer': 58768,\n",
       " 'reign': 126632,\n",
       " 'wasnt': 167980,\n",
       " 'strange': 147499,\n",
       " 'dichotomy': 39376,\n",
       " 'needed': 104216,\n",
       " 'freedom': 58710,\n",
       " 'evidenced': 50108,\n",
       " 'later': 86175,\n",
       " 'structure': 147936,\n",
       " 'ala': 3582,\n",
       " 'couldnt': 32494,\n",
       " 'scifi': 134200,\n",
       " 'adventure': 2212,\n",
       " 'best': 14745,\n",
       " 'mean': 95437,\n",
       " 'worst': 172860,\n",
       " 'statement': 146007,\n",
       " 'comical': 29480,\n",
       " 'bizarre': 15962,\n",
       " 'pink': 116831,\n",
       " 'tinting': 156869,\n",
       " 'unusual': 163801,\n",
       " 'special': 144094,\n",
       " 'effect': 45714,\n",
       " 'make': 92443,\n",
       " 'favorite': 53542,\n",
       " 'late': 86136,\n",
       " 'space': 143794,\n",
       " 'explorer': 51324,\n",
       " 'planet': 117322,\n",
       " 'mar': 93455,\n",
       " 'fight': 54575,\n",
       " 'giant': 62096,\n",
       " 'amoebalike': 5406,\n",
       " 'monster': 99760,\n",
       " 'creature': 33532,\n",
       " 'pretty': 120693,\n",
       " 'coolthe': 31758,\n",
       " 'cast': 23421,\n",
       " 'includes': 75945,\n",
       " 'le': 86796,\n",
       " 'tremayne': 159404,\n",
       " 'naura': 103852,\n",
       " 'hayden': 68438,\n",
       " 'gerald': 61706,\n",
       " 'mohr': 99251,\n",
       " 'jack': 79943,\n",
       " 'kruschen': 84940,\n",
       " 'comfy': 29475,\n",
       " 'enjoy': 47883,\n",
       " 'feel': 53833,\n",
       " 'nod': 105648,\n",
       " 'adding': 1852,\n",
       " 'list': 89094,\n",
       " 'cult': 34620,\n",
       " 'classic': 27467,\n",
       " 'miss': 98618,\n",
       " 'around': 8379,\n",
       " 'animator': 6140,\n",
       " 'bluth': 16956,\n",
       " 'output': 111552,\n",
       " 'company': 29861,\n",
       " 'disney': 41116,\n",
       " 'churning': 26803,\n",
       " 'defected': 37229,\n",
       " 'mouse': 100867,\n",
       " 'form': 57848,\n",
       " 'first': 55957,\n",
       " 'production': 121347,\n",
       " 'secret': 135305,\n",
       " 'nimh': 105403,\n",
       " 'brilliant': 19382,\n",
       " 'feature': 53732,\n",
       " 'hold': 71636,\n",
       " 'day': 36154,\n",
       " 'followed': 57210,\n",
       " 'american': 5233,\n",
       " 'tail': 151351,\n",
       " 'land': 85699,\n",
       " 'involvement': 78439,\n",
       " 'steven': 146473,\n",
       " 'spielberg': 144411,\n",
       " 'commercially': 29686,\n",
       " 'successful': 148855,\n",
       " 'although': 4836,\n",
       " 'none': 105974,\n",
       " 'two': 160954,\n",
       " 'dark': 35772,\n",
       " 'adult': 2140,\n",
       " 'appeal': 7483,\n",
       " 'charming': 25275,\n",
       " 'enjoyable': 47886,\n",
       " 'child': 25982,\n",
       " 'grownup': 65417,\n",
       " 'long': 89897,\n",
       " 'major': 92425,\n",
       " 'misfire': 98482,\n",
       " 'dog': 42009,\n",
       " 'go': 62954,\n",
       " 'heaven': 68934,\n",
       " 'critic': 34004,\n",
       " 'especially': 49158,\n",
       " 'harsh': 68002,\n",
       " 'matter': 94630,\n",
       " 'werent': 169715,\n",
       " 'helped': 69346,\n",
       " 'fact': 52056,\n",
       " 'opened': 110153,\n",
       " 'alongside': 4640,\n",
       " 'little': 89237,\n",
       " 'mermaidconsidering': 96646,\n",
       " 'friendlysounding': 59010,\n",
       " 'title': 156973,\n",
       " 'expect': 50969,\n",
       " 'pleasant': 117646,\n",
       " 'family': 52534,\n",
       " 'fare': 52962,\n",
       " 'provides': 122099,\n",
       " 'surprisingly': 150183,\n",
       " 'story': 147095,\n",
       " 'involving': 78446,\n",
       " 'gambling': 60448,\n",
       " 'deceit': 36862,\n",
       " 'crime': 33812,\n",
       " 'mistreatment': 98825,\n",
       " 'problem': 121116,\n",
       " 'animated': 6101,\n",
       " 'per': 115015,\n",
       " 'call': 21692,\n",
       " 'question': 123521,\n",
       " 'whether': 170220,\n",
       " 'hand': 67128,\n",
       " 'find': 55657,\n",
       " 'much': 101973,\n",
       " 'identity': 74576,\n",
       " 'crisisset': 33954,\n",
       " 'dreary': 43623,\n",
       " 'junkyard': 81974,\n",
       " 'orleans': 110780,\n",
       " 'start': 145876,\n",
       " 'charlie': 25239,\n",
       " 'barkin': 12285,\n",
       " 'roughandtumble': 130865,\n",
       " 'german': 61738,\n",
       " 'shepherd': 138265,\n",
       " 'run': 131344,\n",
       " 'car': 22538,\n",
       " 'courtesy': 32830,\n",
       " 'former': 57893,\n",
       " 'casino': 23364,\n",
       " 'partner': 113733,\n",
       " 'nasty': 103666,\n",
       " 'cigarpuffing': 26863,\n",
       " 'pitbull': 117000,\n",
       " 'carface': 22832,\n",
       " 'albeit': 3658,\n",
       " 'default': 37203,\n",
       " 'whippet': 170330,\n",
       " 'angel': 5910,\n",
       " 'annabelle': 6218,\n",
       " 'tell': 152802,\n",
       " 'unlike': 163110,\n",
       " 'usually': 164467,\n",
       " 'loyal': 90971,\n",
       " 'represents': 127619,\n",
       " 'confused': 30708,\n",
       " 'nature': 103791,\n",
       " 'since': 140196,\n",
       " 'aside': 8923,\n",
       " 'presented': 120503,\n",
       " 'anything': 7067,\n",
       " 'butupon': 21200,\n",
       " 'realizing': 125320,\n",
       " 'he': 68532,\n",
       " 'murdered': 102490,\n",
       " 'steal': 146189,\n",
       " 'earth': 45113,\n",
       " 'reluctant': 127039,\n",
       " 'help': 69343,\n",
       " 'dachshund': 35208,\n",
       " 'pal': 112876,\n",
       " 'itchy': 79253,\n",
       " 'rescue': 127778,\n",
       " 'carfaces': 22833,\n",
       " 'prize': 121061,\n",
       " 'annemarie': 6238,\n",
       " 'human': 73561,\n",
       " 'girl': 62368,\n",
       " 'talk': 151589,\n",
       " 'animal': 6064,\n",
       " 'order': 110521,\n",
       " 'predict': 120094,\n",
       " 'win': 171151,\n",
       " 'rat': 124717,\n",
       " 'race': 123866,\n",
       " 'claim': 27327,\n",
       " 'cutie': 35009,\n",
       " 'reality': 125256,\n",
       " 'using': 164410,\n",
       " 'skill': 140848,\n",
       " 'fortune': 58074,\n",
       " 'elaborate': 46260,\n",
       " 'bring': 19461,\n",
       " 'refuse': 126420,\n",
       " 'admit': 2033,\n",
       " 'grow': 65402,\n",
       " 'annemariethe': 6240,\n",
       " 'concept': 30338,\n",
       " 'isnt': 78913,\n",
       " 'problematic': 121120,\n",
       " 'execution': 50670,\n",
       " 'flamboyant': 56270,\n",
       " 'musical': 102685,\n",
       " 'alligator': 4212,\n",
       " 'appears': 7546,\n",
       " 'threequarters': 155694,\n",
       " 'vocal': 166725,\n",
       " 'pipe': 116915,\n",
       " 'ken': 82962,\n",
       " 'page': 112712,\n",
       " 'emerge': 46900,\n",
       " 'likable': 88491,\n",
       " 'frankly': 58534,\n",
       " 'caring': 22871,\n",
       " 'also': 4747,\n",
       " 'applies': 7623,\n",
       " 'trying': 160180,\n",
       " 'antihero': 6711,\n",
       " 'script': 134724,\n",
       " 'composed': 30167,\n",
       " 'ten': 152915,\n",
       " 'writer': 173191,\n",
       " 'succeeds': 148828,\n",
       " 'rendering': 127300,\n",
       " 'unlovable': 163147,\n",
       " 'audience': 9832,\n",
       " 'empathy': 47076,\n",
       " 'worse': 172776,\n",
       " 'redemption': 126074,\n",
       " 'end': 47278,\n",
       " 'come': 29232,\n",
       " 'across': 1069,\n",
       " 'convincing': 31619,\n",
       " 'damaging': 35405,\n",
       " 'disappointingly': 40595,\n",
       " 'uncharismatic': 161910,\n",
       " 'burt': 20871,\n",
       " 'reynolds': 128785,\n",
       " 'besides': 14722,\n",
       " 'lack': 85287,\n",
       " 'endearing': 47330,\n",
       " 'lead': 86804,\n",
       " 'slowlypaced': 141579,\n",
       " 'place': 117120,\n",
       " 'habit': 66323,\n",
       " 'throwing': 155977,\n",
       " 'extra': 51553,\n",
       " 'serve': 137081,\n",
       " 'purpose': 122960,\n",
       " 'pad': 112666,\n",
       " 'running': 131383,\n",
       " 'aforementioned': 2516,\n",
       " 'resides': 127870,\n",
       " 'danky': 35666,\n",
       " 'sewer': 137337,\n",
       " 'infested': 76633,\n",
       " 'native': 103738,\n",
       " 'seems': 135534,\n",
       " 'thrown': 155980,\n",
       " 'nowhere': 107267,\n",
       " 'try': 160166,\n",
       " 'generosity': 61394,\n",
       " 'feeding': 53830,\n",
       " 'pack': 112627,\n",
       " 'pastelcolored': 113964,\n",
       " 'pup': 122840,\n",
       " 'pizza': 117102,\n",
       " 'whole': 170545,\n",
       " 'screenplay': 134598,\n",
       " 'rough': 130861,\n",
       " 'draft': 43212,\n",
       " 'bit': 15862,\n",
       " 'polish': 118494,\n",
       " 'tighter': 156234,\n",
       " 'impactful': 75331,\n",
       " 'storymatters': 147248,\n",
       " 'lackluster': 85307,\n",
       " 'number': 107515,\n",
       " 'strouse': 147927,\n",
       " 'tj': 157046,\n",
       " 'kuenster': 85002,\n",
       " 'annemaries': 6239,\n",
       " 'song': 143091,\n",
       " 'gator': 60988,\n",
       " 'ballad': 11735,\n",
       " 'good': 63475,\n",
       " 'latter': 86319,\n",
       " 'particular': 113692,\n",
       " 'benefit': 14377,\n",
       " 'mellifluous': 96080,\n",
       " 'uneven': 162551,\n",
       " 'mentioned': 96444,\n",
       " 'stiff': 146558,\n",
       " 'lifeless': 88246,\n",
       " 'detracts': 38843,\n",
       " 'already': 4698,\n",
       " 'unlikeable': 163111,\n",
       " 'fiery': 54532,\n",
       " 'confession': 30609,\n",
       " 'true': 160003,\n",
       " 'intention': 77662,\n",
       " 'toward': 158444,\n",
       " 'dom': 42251,\n",
       " 'deluise': 37703,\n",
       " 'better': 14912,\n",
       " 'role': 130123,\n",
       " 'notably': 106705,\n",
       " 'tiger': 156216,\n",
       " 'jeremy': 80697,\n",
       " 'awesome': 10569,\n",
       " 'small': 141695,\n",
       " 'part': 113615,\n",
       " 'contribution': 31450,\n",
       " 'unremarkable': 163475,\n",
       " 'similarly': 140049,\n",
       " 'wasted': 168040,\n",
       " 'loni': 90060,\n",
       " 'anderson': 5732,\n",
       " 'collie': 29005,\n",
       " 'sired': 140431,\n",
       " 'litter': 89230,\n",
       " 'melba': 96032,\n",
       " 'moore': 100026,\n",
       " 'charles': 25227,\n",
       " 'nelson': 104443,\n",
       " 'reilly': 126645,\n",
       " 'judith': 81780,\n",
       " 'barsi': 12416,\n",
       " 'probably': 121095,\n",
       " 'truly': 160073,\n",
       " 'memorable': 96193,\n",
       " 'partially': 113664,\n",
       " 'sole': 142722,\n",
       " 'legitimately': 87272,\n",
       " 'depressing': 38177,\n",
       " 'joyless': 81640,\n",
       " 'showbarsi': 139064,\n",
       " 'real': 125169,\n",
       " 'positive': 119219,\n",
       " 'animation': 6111,\n",
       " 'technically': 152419,\n",
       " 'imaginative': 75095,\n",
       " 'visuals': 166609,\n",
       " 'bluths': 16957,\n",
       " 'team': 152310,\n",
       " 'standard': 145570,\n",
       " 'particularly': 113701,\n",
       " 'frightening': 59125,\n",
       " 'nightmare': 105273,\n",
       " 'ending': 47401,\n",
       " 'underworld': 162405,\n",
       " 'ruled': 131277,\n",
       " 'gargantuan': 60812,\n",
       " 'satanic': 132734,\n",
       " 'caninedemon': 22205,\n",
       " 'triumph': 159766,\n",
       " 'storytellingon': 147321,\n",
       " 'however': 73198,\n",
       " 'can': 22056,\n",
       " 'not': 106701,\n",
       " 'recommend': 125870,\n",
       " 'entertainment': 48330,\n",
       " 'recognize': 125838,\n",
       " 'fan': 52644,\n",
       " 'climax': 27925,\n",
       " 'admittingly': 2046,\n",
       " 'provide': 122090,\n",
       " 'energy': 47693,\n",
       " 'moving': 101753,\n",
       " 'conclusion': 30425,\n",
       " 'package': 112628,\n",
       " 'league': 86871,\n",
       " 'effort': 45862,\n",
       " 'buff': 20325,\n",
       " 'marvel': 94048,\n",
       " 'lush': 91369,\n",
       " 'artistry': 8674,\n",
       " 'leave': 87010,\n",
       " 'taste': 152049,\n",
       " 'mouth': 100889,\n",
       " 'perv': 115736,\n",
       " 'lesbian': 87565,\n",
       " 'stuffthe': 148159,\n",
       " 'red': 126037,\n",
       " 'wig': 170883,\n",
       " 'lip': 89004,\n",
       " 'silicone': 139918,\n",
       " 'shes': 138332,\n",
       " 'lame': 85590,\n",
       " 'insecure': 77159,\n",
       " 'surferguy': 150054,\n",
       " 'dressing': 43674,\n",
       " 'slutty': 141673,\n",
       " 'weird': 169086,\n",
       " 'definitely': 37326,\n",
       " 'unfashionable': 162613,\n",
       " 'explain': 51204,\n",
       " 'pa': 112547,\n",
       " 'man': 92830,\n",
       " 'oh': 108845,\n",
       " 'poor': 118773,\n",
       " 'dumb': 44394,\n",
       " 'forgot': 57803,\n",
       " 'invention': 78295,\n",
       " 'lousy': 90563,\n",
       " 'actress': 1631,\n",
       " 'plus': 118044,\n",
       " 'waif': 167219,\n",
       " 'look': 90073,\n",
       " 'outthis': 111677,\n",
       " 'melrose': 96130,\n",
       " 'playssurprise': 117607,\n",
       " 'blondshe': 16637,\n",
       " 'think': 154938,\n",
       " 'guy': 66096,\n",
       " 'ewww': 50235,\n",
       " 'guess': 65634,\n",
       " 'sort': 143434,\n",
       " 'psycho': 122384,\n",
       " 'toy': 158542,\n",
       " 'maker': 92476,\n",
       " 'named': 103386,\n",
       " 'joe': 81204,\n",
       " 'petto': 115885,\n",
       " 'living': 89425,\n",
       " 'evil': 50129,\n",
       " 'kill': 83508,\n",
       " 'luck': 91079,\n",
       " 'simply': 140147,\n",
       " 'mutant': 102897,\n",
       " 'robot': 129834,\n",
       " 'son': 143062,\n",
       " 'pino': 116864,\n",
       " 'used': 164328,\n",
       " 'liveeasily': 89321,\n",
       " 'hopefully': 72328,\n",
       " 'presumably': 120618,\n",
       " 'semi': 136186,\n",
       " 'series': 136900,\n",
       " 'previous': 120756,\n",
       " 'soft': 142578,\n",
       " 'core': 31995,\n",
       " 'porn': 119012,\n",
       " 'sex': 137346,\n",
       " 'nudity': 107449,\n",
       " 'low': 90841,\n",
       " 'rent': 127358,\n",
       " 'hybrid': 74103,\n",
       " 'halloween': 66928,\n",
       " 'iii': 74804,\n",
       " 'puppet': 122850,\n",
       " 'doll': 42198,\n",
       " 'supposedly': 149911,\n",
       " 'started': 145889,\n",
       " 'sixth': 140674,\n",
       " 'chapter': 24847,\n",
       " 'abandoned': 96,\n",
       " 'never': 104718,\n",
       " 'completed': 30046,\n",
       " 'hope': 72314,\n",
       " 'stay': 146144,\n",
       " 'oddly': 108263,\n",
       " 'lit': 89170,\n",
       " 'men': 96273,\n",
       " 'woman': 171904,\n",
       " 'beating': 13143,\n",
       " 'crap': 33194,\n",
       " 'boxer': 18460,\n",
       " 'gay': 61060,\n",
       " 'filmafter': 54740,\n",
       " 'badly': 11331,\n",
       " 'bruised': 19948,\n",
       " 'beat': 13127,\n",
       " 'hell': 69235,\n",
       " 'methis': 96961,\n",
       " 'meant': 95538,\n",
       " 'gawk': 61053,\n",
       " 'horror': 72546,\n",
       " 'wonder': 172039,\n",
       " 'lot': 90416,\n",
       " 'airplane': 3426,\n",
       " 'crash': 33318,\n",
       " 'train': 158769,\n",
       " 'wreckif': 173113,\n",
       " 'mediocre': 95744,\n",
       " 'ita': 79106,\n",
       " 'warning': 167761,\n",
       " 'please': 117658,\n",
       " 'eat': 45287,\n",
       " 'beforehand': 13621,\n",
       " 'might': 97439,\n",
       " 'puke': 122630,\n",
       " 'sam': 132219,\n",
       " 'thomas': 155357,\n",
       " 'cavanagh': 23914,\n",
       " 'gray': 64665,\n",
       " 'heather': 68918,\n",
       " 'graham': 64356,\n",
       " 'devoted': 39051,\n",
       " 'sibling': 139526,\n",
       " 'share': 137905,\n",
       " 'apartment': 7287,\n",
       " 'thing': 154781,\n",
       " 'ballroom': 11795,\n",
       " 'dancing': 35543,\n",
       " 'surprise': 150118,\n",
       " 'attractive': 9754,\n",
       " 'bridget': 19291,\n",
       " 'moynahan': 101790,\n",
       " 'historically': 71195,\n",
       " 'heterosexual': 70150,\n",
       " 'feelingsgray': 53866,\n",
       " 'prof': 121419,\n",
       " 'blandest': 16271,\n",
       " 'seen': 135549,\n",
       " 'dull': 44327,\n",
       " 'predictable': 120100,\n",
       " 'unfunny': 162756,\n",
       " 'poorly': 118797,\n",
       " 'acted': 1090,\n",
       " 'written': 173317,\n",
       " 'everything': 50024,\n",
       " 'cheesy': 25640,\n",
       " 'romantic': 130412,\n",
       " 'comedy': 29287,\n",
       " 'twist': 160891,\n",
       " 'sue': 149044,\n",
       " 'kramer': 84786,\n",
       " 'tried': 159588,\n",
       " 'half': 66657,\n",
       " 'cute': 34968,\n",
       " 'stuff': 148117,\n",
       " 'second': 135210,\n",
       " 'serious': 136985,\n",
       " 'actual': 1700,\n",
       " 'acceptance': 700,\n",
       " 'failed': 52194,\n",
       " 'miserably': 98453,\n",
       " 'largely': 85961,\n",
       " 'able': 247,\n",
       " 'took': 157754,\n",
       " 'awkward': 10675,\n",
       " 'tone': 157598,\n",
       " 'got': 64070,\n",
       " 'handled': 67207,\n",
       " 'emotion': 47003,\n",
       " 'phonyi': 116220,\n",
       " 'enjoyed': 47932,\n",
       " 'relationship': 126796,\n",
       " 'authentic': 10092,\n",
       " 'brother': 19794,\n",
       " 'sister': 140478,\n",
       " 'weak': 168745,\n",
       " 'appear': 7504,\n",
       " 'close': 28076,\n",
       " 'natural': 103766,\n",
       " 'tom': 157492,\n",
       " 'unnatural': 163217,\n",
       " 'married': 93891,\n",
       " 'knowing': 84335,\n",
       " 'week': 168935,\n",
       " 'excitement': 50513,\n",
       " 'talked': 151599,\n",
       " 'getting': 61901,\n",
       " 'vega': 165171,\n",
       " 'manner': 93197,\n",
       " 'asking': 8961,\n",
       " 'waiter': 167252,\n",
       " 'involved': 78411,\n",
       " 'unmotivated': 163196,\n",
       " 'charactersthe': 25101,\n",
       " 'mostly': 100571,\n",
       " 'surprising': 150180,\n",
       " 'decent': 36885,\n",
       " 'gave': 61039,\n",
       " 'costars': 32340,\n",
       " 'dud': 44188,\n",
       " 'ringed': 129381,\n",
       " 'false': 52441,\n",
       " 'level': 87797,\n",
       " 'seemed': 135516,\n",
       " 'reading': 125119,\n",
       " 'wooden': 172161,\n",
       " 'showed': 139098,\n",
       " 'nearly': 104069,\n",
       " 'chemistry': 25698,\n",
       " 'non': 105828,\n",
       " 'existent': 50833,\n",
       " 'damaged': 35401,\n",
       " 'phony': 116217,\n",
       " 'rely': 127043,\n",
       " 'molly': 99338,\n",
       " 'shannon': 137860,\n",
       " 'annoying': 6309,\n",
       " 'sissy': 140473,\n",
       " 'spacek': 143828,\n",
       " 'finally': 55628,\n",
       " 'alan': 3606,\n",
       " 'cumming': 34709,\n",
       " 'embarrassing': 46821,\n",
       " 'rating': 124776,\n",
       " 'awful': 10598,\n",
       " 'full': 59511,\n",
       " 'cliche': 27831,\n",
       " 'perplexing': 115504,\n",
       " 'atrotious': 9562,\n",
       " 'wrote': 173442,\n",
       " 'larry': 86021,\n",
       " 'flint': 56721,\n",
       " 'moon': 99983,\n",
       " 'garbage': 60712,\n",
       " 'top': 157907,\n",
       " 'alltime': 4393,\n",
       " 'realize': 125308,\n",
       " 'enough': 48038,\n",
       " 'let': 87715,\n",
       " 'alone': 4566,\n",
       " 'sequel': 136710,\n",
       " 'amazing': 5057,\n",
       " 'piece': 116575,\n",
       " 'trash': 159099,\n",
       " 'shown': 139169,\n",
       " 'released': 126870,\n",
       " 'example': 50301,\n",
       " 'fine': 55678,\n",
       " 'storytelling': 147314,\n",
       " 'superb': 149495,\n",
       " 'inspiring': 77317,\n",
       " 'overly': 112061,\n",
       " 'manipulative': 93123,\n",
       " 'tad': 151282,\n",
       " 'considering': 31018,\n",
       " 'hollywood': 71754,\n",
       " 'restraint': 128135,\n",
       " 'explosion': 51328,\n",
       " 'opportunity': 110348,\n",
       " 'suspenseful': 150363,\n",
       " 'action': 1257,\n",
       " 'thus': 156093,\n",
       " 'focus': 57071,\n",
       " 'extraordinary': 51579,\n",
       " 'ordinary': 110552,\n",
       " 'done': 42360,\n",
       " 'thoroughly': 155410,\n",
       " 'incoherent': 75964,\n",
       " 'rambling': 124327,\n",
       " 'oneand': 109466,\n",
       " 'damned': 35452,\n",
       " 'modern': 99151,\n",
       " 'ridiculous': 129093,\n",
       " 'period': 115366,\n",
       " 'st': 145325,\n",
       " 'century': 24262,\n",
       " 'style': 148367,\n",
       " 'predominate': 120150,\n",
       " 'yawn': 173979,\n",
       " 'manufactured': 93368,\n",
       " 'belaboured': 13981,\n",
       " 'joke': 81323,\n",
       " 'secondary': 135214,\n",
       " 'juvenile': 82108,\n",
       " 'normally': 106554,\n",
       " 'sweep': 150648,\n",
       " 'parodying': 113568,\n",
       " 'original': 110671,\n",
       " 'de': 36394,\n",
       " 'ville': 166267,\n",
       " 'sunset': 149459,\n",
       " 'boulevard': 18314,\n",
       " 'pointless': 118246,\n",
       " 'basic': 12545,\n",
       " 'instinct': 77426,\n",
       " 'characterisation': 24938,\n",
       " 'acceptable': 689,\n",
       " 'scratch': 134456,\n",
       " 'african': 2544,\n",
       " 'created': 33465,\n",
       " 'rhythm': 128875,\n",
       " 'jawbone': 80417,\n",
       " 'virgin': 166443,\n",
       " 'islander': 78854,\n",
       " 'welded': 169162,\n",
       " 'oil': 108942,\n",
       " 'drum': 43988,\n",
       " 'ear': 45016,\n",
       " 'pleasing': 117702,\n",
       " 'steel': 146232,\n",
       " 'band': 11909,\n",
       " 'urban': 164183,\n",
       " 'dj': 41658,\n",
       " 'itch': 79241,\n",
       " 'pursuit': 123009,\n",
       " 'method': 96962,\n",
       " 'creative': 33503,\n",
       " 'expression': 51392,\n",
       " 'wholly': 170582,\n",
       " 'unnarrated': 163214,\n",
       " 'documentary': 41836,\n",
       " 'heart': 68770,\n",
       " 'hiphoprap': 71056,\n",
       " 'movement': 100953,\n",
       " 'explore': 51319,\n",
       " 'genesis': 61408,\n",
       " 'turntablism': 160558,\n",
       " 'art': 8555,\n",
       " 'scratching': 134466,\n",
       " 'vinyl': 166351,\n",
       " 'ultimate': 161492,\n",
       " 'djmc': 41673,\n",
       " 'contempo': 31226,\n",
       " 'reveals': 128470,\n",
       " 'intelligent': 77596,\n",
       " 'articulate': 8619,\n",
       " 'scratcher': 134460,\n",
       " 'startlingly': 145933,\n",
       " 'unique': 162986,\n",
       " ...}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can look at unique words by using 'vocabulary_'\n",
    "\n",
    "vocab.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a45407d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 175730\n",
      "Type of train features: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Type of train features: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape of input data: (39665, 175730)\n",
      "Shape of input data: (9917, 175730)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique words:\", len(vocab.vocabulary_))\n",
    "\n",
    "print(\"Type of train features:\", type(X_train_bow))\n",
    "\n",
    "print(\"Type of train features:\", type(X_test_bow))\n",
    "\n",
    "print(\"Shape of input data:\", X_train_bow.shape)\n",
    "\n",
    "print(\"Shape of input data:\", X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2a76d029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "48 Bytes\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(type(X_train_bow))\n",
    "print(getsizeof(X_train_bow), \"Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda3232",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "\n",
    "Logistic Regression is a statistical model used for binary classification tasks where the goal is to predict the probability of an event occurring. It works by fitting a logistic function to the input data, which maps the input to a probability value between 0 and 1. The logistic function is then used to make predictions by applying a threshold to the probability value, classifying the input as either one of the two possible classes. Logistic Regression is widely used in various fields such as finance, healthcare, and marketing, and can be implemented using various optimization techniques such as gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbf548f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ideapad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2297a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d303d0d4",
   "metadata": {},
   "source": [
    "**accuracy_score**\n",
    "\n",
    "is a function used to evaluate the performance of a classification model by computing the proportion of correct predictions made by the model over the total number of predictions. It is a simple and commonly used metric for evaluating the performance of a model.\n",
    "\n",
    "**classification_report**\n",
    "\n",
    "is a function used to generate a summary report of the classification performance of a model. It includes various metrics such as precision, recall, and F1-score for each class, as well as the overall accuracy of the model. It is a useful tool for gaining insight into the strengths and weaknesses of a model's classification performance, and can be used to compare the performance of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15e030a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8481395583341736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      4939\n",
      "           1       0.85      0.85      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf31985",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**\n",
    "\n",
    "\n",
    "DecisionTreeClassifier is a machine learning algorithm used for classification tasks. It works by constructing a decision tree that recursively splits the input data based on the most important features until the data can be classified into distinct classes. The splitting criteria is determined by maximizing the information gain or minimizing the impurity of the resulting splits. The resulting decision tree can be used to make predictions for new input data by traversing the tree from the root to a leaf node corresponding to the predicted class. DecisionTreeClassifier is widely used in various fields such as finance, healthcare, and marketing, and can be used for both binary and multi-class classification tasks. However, it is prone to overfitting and may require regularization techniques such as pruning to improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6f80d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "373c2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fb36934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7113038217202783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      4939\n",
      "           1       0.71      0.71      0.71      4978\n",
      "\n",
      "    accuracy                           0.71      9917\n",
      "   macro avg       0.71      0.71      0.71      9917\n",
      "weighted avg       0.71      0.71      0.71      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cb282",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**\n",
    "\n",
    "\n",
    "RandomForestClassifier is a machine learning algorithm used for classification tasks. It works by constructing a large number of decision trees (known as an ensemble) and aggregating the results of each tree to make a final prediction. Each tree in the ensemble is trained on a randomly selected subset of the input data and a randomly selected subset of the features, which helps to reduce overfitting and improve generalization performance. The final prediction is determined by a majority vote of the individual tree predictions. RandomForestClassifier is widely used in various fields such as finance, healthcare, and marketing, and is known for its high accuracy and robustness to noisy data. However, it may require more computational resources than other classification algorithms due to its large ensemble of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88ad2698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ae63d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51605f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475345366542301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4939\n",
      "           1       0.85      0.85      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0593f36",
   "metadata": {},
   "source": [
    "\n",
    "**MultinomialNB (Naive Bayes)**\n",
    "\n",
    "MultinomialNB (Naive Bayes) is a machine learning algorithm used for classification tasks, particularly in natural language processing applications. It is based on the Bayes theorem and assumes that the features are conditionally independent given the class label. MultinomialNB is commonly used for text classification tasks, such as sentiment analysis and spam filtering. It works by computing the probability of each class given the input data and selecting the class with the highest probability as the predicted class. The algorithm models the probability distribution of the input features using a multinomial distribution, which assumes that the input features are counts of the frequency of occurrence of each term in a document or corpus. MultinomialNB is known for its simplicity, speed, and good performance in many text classification tasks, but may not be the best choice for data with complex dependencies between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee4f33cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45f31f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c27ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8559040032267823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4939\n",
      "           1       0.87      0.84      0.85      4978\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4ee26",
   "metadata": {},
   "source": [
    "**BernoulliNB (Naive Bayes)**\n",
    "\n",
    "\n",
    "BernoulliNB (Naive Bayes) is a machine learning algorithm used for classification tasks. It is similar to GaussianNB but is designed for binary or boolean features, where each feature takes only two values, 0 or 1. BernoulliNB works by computing the probability of each class given the input data and selecting the class with the highest probability as the predicted class. The algorithm models the probability distribution of the input features using a Bernoulli distribution, which assumes that each feature is a binary random variable with a certain probability of occurrence. BernoulliNB is known for its simplicity, speed, and good performance in many classification tasks, especially when the input features are binary or sparse. However, it may not perform well in cases where the features are highly correlated or have complex dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9c4cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3eed5fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = BernoulliNB()\n",
    "classifier.fit(X_train_bow, y_train_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "761efa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19c57931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85378642734698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4939\n",
      "           1       0.87      0.83      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7453a9",
   "metadata": {},
   "source": [
    "**KNeighborsClassifier**\n",
    "\n",
    "\n",
    "KNeighborsClassifier is a machine learning algorithm used for classification tasks. It works by finding the k-nearest neighbors to the input data point in the feature space and classifying the input data based on the most common class among its k-nearest neighbors. The algorithm uses a distance metric, such as Euclidean or Manhattan distance, to measure the distance between input data points and the training data points. KNeighborsClassifier is a simple and effective algorithm, especially for low-dimensional data, and can handle multi-class classification tasks. However, the algorithm can be sensitive to the choice of k and the distance metric used, and can be computationally expensive for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9d380f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "017a2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbf85617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6110718967429666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60      4939\n",
      "           1       0.61      0.64      0.62      4978\n",
      "\n",
      "    accuracy                           0.61      9917\n",
      "   macro avg       0.61      0.61      0.61      9917\n",
      "weighted avg       0.61      0.61      0.61      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abce444",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**\n",
    "\n",
    "\n",
    "Gradient Boosting Classifier is a machine learning algorithm used for classification tasks. It is a type of boosting algorithm that works by iteratively adding decision trees to an ensemble, with each new tree correcting the errors of the previous trees. GradientBoostingClassifier optimizes the loss function of the model using gradient descent to find the optimal parameters of each tree. It is a powerful algorithm that can handle complex interactions between features and is known for its high accuracy in many classification tasks. However, it can be sensitive to the choice of hyperparameters and may require careful tuning to achieve good performance. GradientBoostingClassifier is widely used in various fields such as finance, healthcare, and marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acea6fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88c1440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20419c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7920742159927397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78      4939\n",
      "           1       0.76      0.85      0.80      4978\n",
      "\n",
      "    accuracy                           0.79      9917\n",
      "   macro avg       0.80      0.79      0.79      9917\n",
      "weighted avg       0.80      0.79      0.79      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143f33a",
   "metadata": {},
   "source": [
    "**AdaBoost Classifier**\n",
    "\n",
    "AdaBoostClassifier is a machine learning algorithm used for classification tasks. It is a type of boosting algorithm that works by iteratively adding weak classifiers to an ensemble, with each new classifier focused on classifying the misclassified samples of the previous classifiers. AdaBoostClassifier assigns a weight to each training sample, which is updated after each iteration based on the accuracy of the previous classifiers. The final prediction is determined by a weighted majority vote of the individual classifier predictions. AdaBoostClassifier is a powerful algorithm that can improve the performance of weak classifiers and is known for its ability to handle complex classification problems. However, it can be sensitive to noisy data and outliers and may require careful tuning of hyperparameters to achieve good performance. AdaBoostClassifier is widely used in various fields such as finance, healthcare, and marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd6bfede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd9a5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02e7c3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7868306947665624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.78      4939\n",
      "           1       0.76      0.83      0.80      4978\n",
      "\n",
      "    accuracy                           0.79      9917\n",
      "   macro avg       0.79      0.79      0.79      9917\n",
      "weighted avg       0.79      0.79      0.79      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b455e9a",
   "metadata": {},
   "source": [
    "**XGB Classifier**\n",
    "\n",
    "XGB Classifier (Extreme Gradient Boosting Classifier) is a machine learning algorithm used for classification tasks. It is a type of boosting algorithm that works by iteratively adding decision trees to an ensemble, with each new tree focused on reducing the errors of the previous trees. XGBClassifier optimizes the loss function of the model using gradient descent to find the optimal parameters of each tree. It also uses regularization techniques to prevent overfitting and improve generalization performance. XGBClassifier is known for its high accuracy and speed in many classification tasks, especially in large-scale and high-dimensional datasets. It can handle missing data and outliers and can automatically handle feature selection and feature engineering. However, it may require careful tuning of hyperparameters and can be computationally expensive for very large datasets. XGBClassifier is widely used in various fields such as finance, healthcare, and marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b196f870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "classifier = xgb.XGBClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03b45780",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54e5e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846324493294343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      4939\n",
      "           1       0.83      0.87      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559761a",
   "metadata": {},
   "source": [
    "# In Bag of Words LogisticRegression is giving good accuracy with Instant time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a325c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e395e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637467b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82dfcd58",
   "metadata": {},
   "source": [
    "# Term Frequency Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7740070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0f8971f7",
   "metadata": {},
   "source": [
    "**Term Frequency Inverse Document Frequency**\n",
    "\n",
    "\n",
    "In BOW approach all the words in the text are treated as equally important i.e. there's no notion of some words in the document being more important than others. TF-IDF, or term frequency-inverse document frequency, addresses this issue. It aims to quantify the importance of a given word relative to other words in the document and in the corpus.\n",
    "\n",
    "Let's now try to understand:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    " \n",
    " \n",
    "Advantages\n",
    "If the word is rare in the corpus, it will be given more importance. (i.e. IDF)\n",
    "If the word is more frequent in a document, it will be given more importance. (i.e. TF)\n",
    "Disadvantages\n",
    "Same as BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9bfcf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e8c26a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRAMS'] = df.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b9cd9930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>GRAMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                               GRAMS  \n",
       "0  one reviewer mentioned watching oz episode you...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bcbfc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f35a710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mentioned watching oz episode you...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there family little boy jake think t...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job wasnt creative or...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary school nu...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movie high art fan expec...\n",
       "Name: GRAMS, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5ba590ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4bdf720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 49582, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "79490228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ngrams, X_test_ngrams, y_train_ngrams, y_test_ngrams = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8e4272b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "X_train_ngrams = vectorizer.fit_transform(X_train_ngrams)\n",
    "X_test_ngrams = vectorizer.transform(X_test_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea658a5",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "616c957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ideapad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1d9b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8930119995966522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      4939\n",
      "           1       0.88      0.91      0.89      4978\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_ngrams, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4ed94",
   "metadata": {},
   "source": [
    "**MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a05800ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      4939\n",
      "           1       0.89      0.88      0.88      4978\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dc344",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b67c7",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8501d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c5ed1e",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefe1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b4bb3",
   "metadata": {},
   "source": [
    "**AdaBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2323df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e92c3",
   "metadata": {},
   "source": [
    "**XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d68c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2d9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0232bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a4775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f5ac112",
   "metadata": {},
   "source": [
    "**Latent Space**\n",
    "\n",
    "A latent space, also known as a latent feature space or embedding space, is an embedding of a set of items within a manifold in which items which resemble each other more closely are positioned closer to one another in the latent space.\n",
    "\n",
    "**Word Embeddings (Word Vectors)**\n",
    "\n",
    "In natural language processing (NLP), word embedding is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning. Word embeddings can be obtained using a set of language modeling and feature learning techniques where words or phrases from the vocabulary are mapped to vectors of real numbers.\n",
    "\n",
    "Methods to generate this mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, explainable knowledge base method, and explicit representation in terms of the context in which words appear.\n",
    "\n",
    "Traditionally, one of the main limitations of word embeddings (word vector space models in general) is that words with multiple meanings are conflated into a single representation (a single vector in the semantic space). In other words, polysemy and homonymy are not handled properly.\n",
    "\n",
    "Word2Vec\n",
    "\"You shall know the word by the company it keeps.\" by JR Firth\n",
    "\n",
    "Distributional Semantics (i.e. a word is characterized by the company it keeps)\n",
    "W2v works well because there is an idea of meaning distribution in the context.\n",
    "\n",
    "Algorithms to generate Word2Vec Embeddings\n",
    "\n",
    "SkipGram\n",
    "Continuous Bag of Words\n",
    "Issue\n",
    "Even if the word is having three different meaning, W2v will return the weighted average of all three as the output. Now the question is,\n",
    "\n",
    "Is it possible to segregate the three vectors to represent the words based in the context?\n",
    "Is it possible to disambiguate the word vectors based on the context?\n",
    "Word2Vec is not capturing the contextual information. This is where BERT comes handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fbc12e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from gensim) (1.10.0)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.0\n",
      "    Uninstalling gensim-4.3.0:\n",
      "      Successfully uninstalled gensim-4.3.0\n",
      "Successfully installed gensim-4.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "16940521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim version :  4.3.1\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "print(\"gensim version : \", gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "631bf351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b5e4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenised_sentences'] = df.review.apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce201dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "model = Word2Vec(list(df.tokenised_sentences), vector_size=100, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "104dfa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=203586, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c69f23b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49582"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Documents\n",
    "\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3056e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26207083  0.7223034  -0.01432159 -0.50564283 -0.35594425 -0.553433\n",
      "  0.21808168  0.84362996 -0.5382072  -0.6066464  -0.07808664 -0.3173889\n",
      "  0.1931239  -0.04034117  0.21059242 -0.4110812   0.29875034 -0.6322992\n",
      " -0.2702785  -0.30932644  0.02614106 -0.01208641  0.507076   -0.26182258\n",
      " -0.5367741   0.34802997  0.1251767  -0.45231742 -0.13653734  0.33049774\n",
      "  0.43048614 -0.04450234  0.02773081  0.02596193 -0.03257094  0.48451364\n",
      "  0.5468732   0.39476764 -0.14968957 -0.27230453  0.13983625 -0.01988788\n",
      "  0.0461325   0.08418711  0.30990615 -0.47561106 -0.37876514 -0.01386426\n",
      " -0.14856163 -0.1168834  -0.11509139 -0.5064927  -0.13584884  0.04501256\n",
      " -0.42963067  0.4183924   0.40514877 -0.01690827  0.08214913 -0.0423041\n",
      " -0.05339326  0.269902   -0.11362849 -0.41674963  0.05627399  0.19315228\n",
      " -0.01416448  0.36881173 -0.38916174 -0.30462298  0.24152151  0.33337158\n",
      "  0.44847116  0.08208382  0.1315218   0.45530093 -0.05304606  0.3324164\n",
      " -0.5306401   0.06659745 -0.28154793  0.30370933 -0.18753387  0.22257018\n",
      "  0.20405781  0.10126714 -0.220362    0.26046458 -0.22172004  0.4840202\n",
      "  0.7323584   0.24825633 -0.43460074  0.12964106  0.64076394  0.32971984\n",
      " -0.00176534 -0.5561114   0.2303855   0.16705929]\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# access the 100 dimensional vector for one of the words\n",
    "\n",
    "print(model.wv.__getitem__('foolish'))\n",
    "\n",
    "print(model.wv.__getitem__('foolish').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df257a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.8362365e+00 -1.1548115e+00 -5.6796622e-01 ... -6.4830616e-02\n",
      "   3.8143861e-01 -7.7012092e-01]\n",
      " [ 1.0719911e+00 -7.4609637e-01  1.7836919e-01 ...  8.1568038e-01\n",
      "  -8.5344422e-01 -3.7824184e-01]\n",
      " [ 1.9048986e+00  3.2454956e-01 -1.9198608e-01 ...  2.1799347e+00\n",
      "   9.3147659e-01 -8.2617128e-01]\n",
      " ...\n",
      " [ 1.1033059e-02  1.9939778e-02 -2.2497594e-03 ...  2.3545222e-03\n",
      "  -3.0235504e-04  1.2652064e-03]\n",
      " [-1.9600246e-02  1.1683275e-02  1.9828521e-02 ...  2.3179364e-03\n",
      "  -1.7069021e-02  2.7690077e-02]\n",
      " [-1.0943047e-02  2.0388147e-02  1.3369661e-02 ... -2.5068441e-02\n",
      "  -6.5760263e-03  1.2705567e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Access the 100D vectors for all 6 words\n",
    "\n",
    "print(model.wv.__getitem__(model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c639c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model\n",
    "sentences = [text.split() for text in df['GRAMS'].tolist()]\n",
    "model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
    "\n",
    "\n",
    "# create document vectors\n",
    "def get_doc_vector(tokens):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vectors.append(model.wv[token])\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "df['doc_vector_w2v'] = df['GRAMS'].apply(lambda x: get_doc_vector(x.split()))\n",
    "\n",
    "# convert document vectors to numpy array\n",
    "vectors = np.stack(df['doc_vector_w2v'].values)\n",
    "vectors = vectors.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28de86ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>GRAMS</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>doc_vector_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, oz, episo...</td>\n",
       "      <td>[0.048915178, 0.47394133, -0.024953146, 0.0335...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[-0.2685939, 0.27007356, -0.09775053, 0.128432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[-0.11369068, 0.2901203, 0.17621964, 0.1237306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "      <td>[-0.11817372, 0.6315114, 0.04626782, 0.1566619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[0.0009595299, 0.3264597, 0.2392574, 0.2339540...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                               GRAMS  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [one, reviewer, mentioned, watching, oz, episo...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, there, family, little, boy, jake, ...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "                                      doc_vector_w2v  \n",
       "0  [0.048915178, 0.47394133, -0.024953146, 0.0335...  \n",
       "1  [-0.2685939, 0.27007356, -0.09775053, 0.128432...  \n",
       "2  [-0.11369068, 0.2901203, 0.17621964, 0.1237306...  \n",
       "3  [-0.11817372, 0.6315114, 0.04626782, 0.1566619...  \n",
       "4  [0.0009595299, 0.3264597, 0.2392574, 0.2339540...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdef272",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23f54833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8733d0",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f392f50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8630634264394474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      4939\n",
      "           1       0.86      0.87      0.86      4978\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ideapad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947e949",
   "metadata": {},
   "source": [
    "**BernoulliNB (Naive Bayes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67386e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7427649490773419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      4939\n",
      "           1       0.76      0.71      0.74      4978\n",
      "\n",
      "    accuracy                           0.74      9917\n",
      "   macro avg       0.74      0.74      0.74      9917\n",
      "weighted avg       0.74      0.74      0.74      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383831c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362edb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e5d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac800cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f65b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b537f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb380cbf",
   "metadata": {},
   "source": [
    "**Deep Learning**\n",
    "\n",
    "\n",
    "\n",
    "Deep learning is a subset of machine learning that is based on artificial neural networks that simulate the way the human brain works. It involves training a model on a large dataset to learn complex representations of data, with the aim of achieving high accuracy on a given task, such as image or speech recognition, natural language processing, and decision making. Deep learning models typically have multiple layers of artificial neurons, which are trained using backpropagation to adjust the weights and biases in order to minimize the error between the predicted output and the actual output. The main advantage of deep learning is its ability to automatically extract features from raw data, making it possible to solve a wide range of complex problems with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa710d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c86aa5",
   "metadata": {},
   "source": [
    "**An Artificial Neural Network (ANN)**\n",
    "\n",
    "\n",
    "An Artificial Neural Network (ANN) classifier is a type of machine learning model that learns to map input data to output classes by training on a set of labeled examples. It consists of multiple layers of interconnected nodes (neurons), each performing a linear or nonlinear operation on its input and passing the result to the next layer. The first layer receives the input data, and the final layer produces the output class predictions. During training, the model adjusts the weights of the connections between the neurons to minimize the difference between its predictions and the true labels of the training examples. ANN classifiers are widely used for tasks such as image classification, natural language processing, and speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7ac060b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1240/1240 [==============================] - 6s 4ms/step - loss: 0.4288 - accuracy: 0.8279 - val_loss: 0.2862 - val_accuracy: 0.8827\n",
      "Epoch 2/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.2423 - accuracy: 0.9043 - val_loss: 0.2721 - val_accuracy: 0.8913\n",
      "Epoch 3/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.2052 - accuracy: 0.9215 - val_loss: 0.2758 - val_accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.1843 - accuracy: 0.9310 - val_loss: 0.2899 - val_accuracy: 0.8902\n",
      "Epoch 5/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.1673 - accuracy: 0.9387 - val_loss: 0.3059 - val_accuracy: 0.8850\n",
      "Epoch 6/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.1550 - accuracy: 0.9433 - val_loss: 0.3196 - val_accuracy: 0.8847\n",
      "Epoch 7/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.1452 - accuracy: 0.9475 - val_loss: 0.3428 - val_accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.1368 - accuracy: 0.9518 - val_loss: 0.3554 - val_accuracy: 0.8794\n",
      "Epoch 9/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.1291 - accuracy: 0.9554 - val_loss: 0.3742 - val_accuracy: 0.8756\n",
      "Epoch 10/10\n",
      "1240/1240 [==============================] - 5s 4ms/step - loss: 0.1218 - accuracy: 0.9577 - val_loss: 0.3909 - val_accuracy: 0.8726\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
    "\n",
    "# Convert the tokenized text data to sequences of integers\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['GRAMS'])\n",
    "sequences = tokenizer.texts_to_sequences(df['GRAMS'])\n",
    "\n",
    "# Pad sequences to have same length\n",
    "\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert target labels to binary format\n",
    "\n",
    "targets = np.array(df['sentiment'])\n",
    "targets = np.where(targets==1, 1, 0)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Embedding(10000, 16, input_length=200),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(padded_sequences, targets, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(['your test data goes here'])\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200)\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "12f6216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.9-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.10.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 2.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.1.0-cp310-cp310-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.4/120.4 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.18.0-py2.py3-none-any.whl (178 kB)\n",
      "     -------------------------------------- 178.9/178.9 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ideapad\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.10-py3-none-any.whl size=1480617 sha256=c6312450c43aadeed571a20df375a5600cc6812678076a7ad6633df8601df1e8\n",
      "  Stored in directory: c:\\users\\ideapad\\appdata\\local\\pip\\cache\\wheels\\f8\\55\\5b\\9dde9a2af48db48d64b8cc3877f0670cf11c5d78de392c3f05\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, opt-einsum, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.5.9 gast-0.4.0 google-auth-2.18.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 jax-0.4.10 keras-2.12.0 libclang-16.0.0 ml-dtypes-0.1.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261debc0",
   "metadata": {},
   "source": [
    "**Recurrent Neural Networks (RNNs)**\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a type of neural network designed for processing sequential data. They are characterized by having a hidden state that is updated at each time step based on the current input and the previous hidden state. RNNs are capable of processing input sequences of variable length, making them useful for tasks such as language modeling, machine translation, and speech recognition. However, they suffer from the vanishing gradient problem, which can make it difficult to train them on long sequences. To overcome this problem, variants of RNNs such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) have been developed, which incorporate additional mechanisms to control the flow of information through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6c053",
   "metadata": {},
   "source": [
    "**LSTM (Long Short-Term Memory)**\n",
    "\n",
    "\n",
    "LSTM (Long Short-Term Memory) is a type of recurrent neural network (RNN) that is designed to avoid the vanishing gradient problem. LSTMs are used for modeling sequential data such as time series, speech, and text. LSTMs have a unique memory cell that can maintain information over long periods of time, and they use gates to control the flow of information into and out of the cell. These gates allow the LSTM to selectively forget or remember information from previous time steps, and they also allow the LSTM to add new information to the memory cell. LSTMs have shown to be effective for a wide range of tasks, including language modeling, machine translation, speech recognition, and image captioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1e1c587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1240/1240 [==============================] - 127s 102ms/step - loss: 0.3548 - accuracy: 0.8404 - val_loss: 0.3014 - val_accuracy: 0.8840\n",
      "Epoch 2/10\n",
      "1240/1240 [==============================] - 117s 94ms/step - loss: 0.2255 - accuracy: 0.9141 - val_loss: 0.2870 - val_accuracy: 0.8848\n",
      "Epoch 3/10\n",
      "1240/1240 [==============================] - 137s 111ms/step - loss: 0.1869 - accuracy: 0.9294 - val_loss: 0.3421 - val_accuracy: 0.8761\n",
      "Epoch 4/10\n",
      "1240/1240 [==============================] - 140s 113ms/step - loss: 0.1550 - accuracy: 0.9433 - val_loss: 0.3457 - val_accuracy: 0.8693\n",
      "Epoch 5/10\n",
      "1240/1240 [==============================] - 126s 102ms/step - loss: 0.1320 - accuracy: 0.9525 - val_loss: 0.3997 - val_accuracy: 0.8741\n",
      "Epoch 6/10\n",
      "1240/1240 [==============================] - 121s 98ms/step - loss: 0.1070 - accuracy: 0.9633 - val_loss: 0.4284 - val_accuracy: 0.8695\n",
      "Epoch 7/10\n",
      "1240/1240 [==============================] - 116s 94ms/step - loss: 0.0911 - accuracy: 0.9700 - val_loss: 0.4746 - val_accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "1240/1240 [==============================] - 115s 93ms/step - loss: 0.0730 - accuracy: 0.9758 - val_loss: 0.5017 - val_accuracy: 0.8631\n",
      "Epoch 9/10\n",
      "1240/1240 [==============================] - 113s 91ms/step - loss: 0.0703 - accuracy: 0.9768 - val_loss: 0.4862 - val_accuracy: 0.8597\n",
      "Epoch 10/10\n",
      "1240/1240 [==============================] - 119s 96ms/step - loss: 0.0599 - accuracy: 0.9808 - val_loss: 0.5617 - val_accuracy: 0.8565\n",
      "1/1 [==============================] - 0s 266ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Convert the tokenized text data to sequences of integers\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['GRAMS'])\n",
    "sequences = tokenizer.texts_to_sequences(df['GRAMS'])\n",
    "\n",
    "# Pad sequences to have same length\n",
    "\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert target labels to binary format\n",
    "\n",
    "targets = np.array(df['sentiment'])\n",
    "targets = np.where(targets==1, 1, 0)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Embedding(10000, 16, input_length=200),\n",
    "    LSTM(16),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(padded_sequences, targets, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(['your test data goes here'])\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200)\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0014c2b",
   "metadata": {},
   "source": [
    "**Gated Recurrent Unit (GRU)**\n",
    "\n",
    "Gated Recurrent Unit (GRU) is a type of recurrent neural network (RNN) architecture that is similar to LSTM but has fewer parameters, making it faster to train and less prone to overfitting. GRUs also use gating mechanisms to control the flow of information, but unlike LSTMs, they have only two gates: reset and update gates. The reset gate helps the network decide how to combine the new input with the previous hidden state, while the update gate helps the network decide how much of the previous hidden state to keep and how much to discard. Overall, GRUs have shown promising results in various natural language processing (NLP) tasks such as language translation and text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a1572552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1240/1240 [==============================] - 121s 96ms/step - loss: 0.3720 - accuracy: 0.8269 - val_loss: 0.2915 - val_accuracy: 0.8793\n",
      "Epoch 2/10\n",
      "1240/1240 [==============================] - 119s 96ms/step - loss: 0.2302 - accuracy: 0.9110 - val_loss: 0.2904 - val_accuracy: 0.8864\n",
      "Epoch 3/10\n",
      "1240/1240 [==============================] - 122s 99ms/step - loss: 0.1923 - accuracy: 0.9287 - val_loss: 0.3162 - val_accuracy: 0.8812\n",
      "Epoch 4/10\n",
      "1240/1240 [==============================] - 119s 96ms/step - loss: 0.1615 - accuracy: 0.9424 - val_loss: 0.3482 - val_accuracy: 0.8807\n",
      "Epoch 5/10\n",
      "1240/1240 [==============================] - 123s 99ms/step - loss: 0.1335 - accuracy: 0.9545 - val_loss: 0.3751 - val_accuracy: 0.8721\n",
      "Epoch 6/10\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.1134 - accuracy: 0.9614 - val_loss: 0.3964 - val_accuracy: 0.8708\n",
      "Epoch 7/10\n",
      "1240/1240 [==============================] - 124s 100ms/step - loss: 0.0937 - accuracy: 0.9693 - val_loss: 0.4278 - val_accuracy: 0.8703\n",
      "Epoch 8/10\n",
      "1240/1240 [==============================] - 118s 95ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 0.4387 - val_accuracy: 0.8683\n",
      "Epoch 9/10\n",
      "1240/1240 [==============================] - 131s 105ms/step - loss: 0.0690 - accuracy: 0.9782 - val_loss: 0.5028 - val_accuracy: 0.8691\n",
      "Epoch 10/10\n",
      "1240/1240 [==============================] - 126s 101ms/step - loss: 0.0535 - accuracy: 0.9844 - val_loss: 0.5306 - val_accuracy: 0.8657\n",
      "1/1 [==============================] - 0s 199ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "# Convert the tokenized text data to sequences of integers\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['GRAMS'])\n",
    "sequences = tokenizer.texts_to_sequences(df['GRAMS'])\n",
    "\n",
    "# Pad sequences to have same length\n",
    "\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert target labels to binary format\n",
    "\n",
    "targets = np.array(df['sentiment'])\n",
    "targets = np.where(targets==1, 1, 0)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Embedding(10000, 16, input_length=200),\n",
    "    GRU(16),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(padded_sequences, targets, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(['your test data goes here'])\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200)\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30627e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
